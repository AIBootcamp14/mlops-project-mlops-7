# dataset.py
# TODOê°€ ì•„ë‹Œ ë¶€ë¶„ë„ ì–¼ë§ˆë“ ì§€ ìˆ˜ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.
# ë‹¨, ìˆ˜ì • ê¸ˆì§€ë¼ê³  ì“°ì—¬ìˆëŠ” í•­ëª©ì— ëŒ€í•´ì„œëŠ” ìˆ˜ì •í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”. (ë¶ˆê°€í”¼í•˜ê²Œ ìˆ˜ì •ì´ í•„ìš”í•  ê²½ìš° ë©”ì¼ë¡œ ë¯¸ë¦¬ ë¬¸ì˜)

import os
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset
from utils import get_data_path
from sklearn.preprocessing import LabelEncoder

print("Current Working Directory:", os.getcwd())
SYMBOLS = ['Customer', 'Discount', 'Marketing', 'Onlinesales', 'Tax']  # !!! ìˆ˜ì • ê¸ˆì§€ !!!

CATEGORY_MAP = {
    'Fun': 'Lifestyle',
    'More Bags': 'Bags',
    'Backpacks': 'Bags',
    'Google': 'Nest'
}

MONTH_MAP = {
    1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr',
    5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug',
    9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'
}

class InfoDataset(Dataset):
    def __init__(self, is_training=True, in_columns=None, out_columns=None, data_dir='../data'):
        if in_columns is None:
            in_columns = ['ê³ ê°ID', 'ê±°ë˜ID', 'ê±°ë˜ë‚ ì§œ', 'ì œí’ˆID', 'ì œí’ˆì¹´í…Œê³ ë¦¬', 'ìˆ˜ëŸ‰', 'í‰ê· ê¸ˆì•¡', 'ë°°ì†¡ë£Œ', 'ì¿ í°ìƒíƒœ',
                          'ì„±ë³„', 'ê³ ê°ì§€ì—­', 'ê°€ì…ê¸°ê°„', 'GST', 'ì›”', 'ì¿ í°ì½”ë“œ', 'í• ì¸ìœ¨', 'ê±°ë˜ê¸ˆì•¡']
        if out_columns is None:
            out_columns = ['ì œí’ˆì¹´í…Œê³ ë¦¬']

        self.x, self.y = make_features(in_columns, out_columns, is_training, data_dir)
        self.x = torch.from_numpy(self.x).float()
        self.y = torch.from_numpy(self.y).float()

    def __len__(self):
        return len(self.x)

    def __getitem__(self, idx):
        return self.x[idx], self.y[idx]


def make_features(in_columns, out_columns, is_training, data_dir='data'):
    save_fname = 'merged_data.pkl'
    merged_path = os.path.join(data_dir, save_fname)

    if os.path.exists(merged_path):
        print(f'loading from {merged_path}')
        df = pd.read_pickle(merged_path)
    else:
        print('merging raw csv files...')
        df = merge_data(SYMBOLS, data_dir)
        df.to_pickle(merged_path)
        print(f'saved to {merged_path}')

    df.dropna(subset=out_columns, inplace=True)
    df.fillna(0, inplace=True)

    # ë¬¸ìì—´í˜• ì»¬ëŸ¼ ì¸ì½”ë”©
    label_cols = ['ì„±ë³„', 'ê³ ê°ì§€ì—­', 'ì¿ í°ì½”ë“œ', 'ì›”', 'ê³ ê°ID', 'ê±°ë˜ID', 'ì œí’ˆID', 'ì¿ í°ìƒíƒœ']
    for col in label_cols:
        if col in df.columns:
            df[col] = LabelEncoder().fit_transform(df[col].astype(str))

    # íƒ€ê²Ÿ ì¸ì½”ë”©
    df['ì œí’ˆì¹´í…Œê³ ë¦¬'] = LabelEncoder().fit_transform(df['ì œí’ˆì¹´í…Œê³ ë¦¬'])

    df = df[in_columns + out_columns]
    df = df.loc[:, ~df.columns.duplicated()]

    x = df[in_columns].to_numpy().astype(float)
    y = df[out_columns].to_numpy().astype(float).squeeze()

    if is_training:
        return x[:-100], y[:-100]
    else:
        return x[-100:], y[-100:]


def merge_data(symbols, data_dir):
    print("merging raw csv files...")
    dfs = {symbol: pd.read_csv(get_data_path(symbol, data_dir)) for symbol in symbols}

    # ë³‘í•© ìˆœì„œ: Onlinesales + Customer â†’ Tax â†’ Discount
    merged = pd.merge(dfs['Onlinesales'], dfs['Customer'], on='ê³ ê°ID')
    merged = pd.merge(merged, dfs['Tax'], on='ì œí’ˆì¹´í…Œê³ ë¦¬')

    # ì œí’ˆì¹´í…Œê³ ë¦¬ ë§¤í•‘
    merged['ì œí’ˆì¹´í…Œê³ ë¦¬'] = merged['ì œí’ˆì¹´í…Œê³ ë¦¬'].map(CATEGORY_MAP).fillna(merged['ì œí’ˆì¹´í…Œê³ ë¦¬'])

    # Discountì—ì„œ 'Notebooks' ì œì™¸
    discount_df = dfs['Discount'][dfs['Discount']['ì œí’ˆì¹´í…Œê³ ë¦¬'] != 'Notebooks'].copy()

    # ì›” íŒŒìƒ í›„ ë¬¸ìì—´ë¡œ ë§¤í•‘
    merged['ì›”'] = pd.to_datetime(merged['ê±°ë˜ë‚ ì§œ']).dt.month.map(MONTH_MAP)

    # Discount ë³‘í•©
    merged = pd.merge(merged, discount_df, on=['ì œí’ˆì¹´í…Œê³ ë¦¬', 'ì›”'])

    # ê±°ë˜ë‚ ì§œ ì •ìˆ˜í™”
    merged['ê±°ë˜ë‚ ì§œ'] = pd.to_datetime(merged['ê±°ë˜ë‚ ì§œ'], errors='coerce')
    merged['ê±°ë˜ë‚ ì§œ'] = merged['ê±°ë˜ë‚ ì§œ'].dt.strftime('%Y%m%d').astype(float)

    # ê±°ë˜ê¸ˆì•¡ ê³µì‹ ì ìš©
    merged['ê±°ë˜ê¸ˆì•¡'] = merged['í‰ê· ê¸ˆì•¡'] * merged['ìˆ˜ëŸ‰'] * (1 + merged['GST']) + merged['ë°°ì†¡ë£Œ']

    print("ğŸ” ìµœì¢… ë³‘í•©ëœ ì»¬ëŸ¼ ëª©ë¡:", merged.columns.tolist())
    return merged






if __name__ == "__main__":
    dataset = InfoDataset(is_training=True)
    print(f"dataset length: {len(dataset)}")
    print(f"x shape: {dataset.x.shape}, y shape: {dataset.y.shape}")
    print("first sample x:", dataset[0][0])
    print("first sample y:", dataset[0][1])
    print("x[:5] (list):", dataset.x[:5].tolist())
    print("y[:5] (list):", dataset.y[:5].tolist())

    # âœ… í´ë˜ìŠ¤ ìˆ˜ í™•ì¸
    import numpy as np
    unique_classes, counts = np.unique(dataset.y.numpy(), return_counts=True)
    print("\nğŸ“Š í´ë˜ìŠ¤ ê°œìˆ˜:", len(unique_classes))
    print("ğŸ§© í´ë˜ìŠ¤ ëª©ë¡:", unique_classes.tolist())
    print("ğŸ”¢ í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜:")
    for c, n in zip(unique_classes, counts):
        print(f" - í´ë˜ìŠ¤ {int(c)}: {n}ê°œ")

    # âœ… ì…ë ¥ í”¼ì²˜ êµ¬ì„± í™•ì¸
    in_columns = [
        'ê³ ê°ID', 'ê±°ë˜ID', 'ê±°ë˜ë‚ ì§œ', 'ì œí’ˆID', 'ì œí’ˆì¹´í…Œê³ ë¦¬', 'ìˆ˜ëŸ‰', 'í‰ê· ê¸ˆì•¡', 'ë°°ì†¡ë£Œ', 'ì¿ í°ìƒíƒœ',
        'ì„±ë³„', 'ê³ ê°ì§€ì—­', 'ê°€ì…ê¸°ê°„', 'GST', 'ì›”', 'ì¿ í°ì½”ë“œ', 'í• ì¸ìœ¨', 'ê±°ë˜ê¸ˆì•¡']
    print("\nğŸ§¾ ì…ë ¥ í”¼ì²˜ ëª©ë¡:")
    for idx, col in enumerate(in_columns):
        print(f"[{idx}] {col}")

