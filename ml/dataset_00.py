# dataset.py
# TODOê°€ ì•„ë‹Œ ë¶€ë¶„ë„ ì–¼ë§ˆë“ ì§€ ìˆ˜ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.
# ë‹¨, ìˆ˜ì • ê¸ˆì§€ë¼ê³  ì“°ì—¬ìˆëŠ” í•­ëª©ì— ëŒ€í•´ì„œëŠ” ìˆ˜ì •í•˜ì§€ ë§ì•„ì£¼ì„¸ìš”. (ë¶ˆê°€í”¼í•˜ê²Œ ìˆ˜ì •ì´ í•„ìš”í•  ê²½ìš° ë©”ì¼ë¡œ ë¯¸ë¦¬ ë¬¸ì˜)

import os
import numpy as np
import pandas as pd
import torch
from torch.utils.data import Dataset
from utils import get_data_path

from sklearn.preprocessing import LabelEncoder

print("Current Working Directory:", os.getcwd())
SYMBOLS = ['Customer', 'Discount', 'Marketing', 'Onlinesales', 'Tax']  # !!! ìˆ˜ì • ê¸ˆì§€ !!!


class InfoDataset(Dataset):
    def __init__(self, 
                 is_training=True, 
                 in_columns=None, 
                 out_columns=None,
                 data_dir='../data'):
        
        if in_columns is None:
            in_columns = ['ê³ ê°ID', 'ê±°ë˜ID', 'ê±°ë˜ë‚ ì§œ', 'ì œí’ˆID', 'ì œí’ˆì¹´í…Œê³ ë¦¬', 'ìˆ˜ëŸ‰', 'í‰ê· ê¸ˆì•¡', 'ë°°ì†¡ë£Œ', 'ì¿ í°ìƒíƒœ',
                          'ì„±ë³„', 'ê³ ê°ì§€ì—­', 'ê°€ì…ê¸°ê°„', 'GST', 'ì›”', 'ì¿ í°ì½”ë“œ', 'í• ì¸ìœ¨', 'ê±°ë˜ê¸ˆì•¡']
        if out_columns is None:
            out_columns = ['ì œí’ˆì¹´í…Œê³ ë¦¬']

        self.x, self.y = make_features(in_columns, out_columns, is_training, data_dir)
        self.x = torch.from_numpy(self.x).float()
        self.y = torch.from_numpy(self.y).float()

    def __len__(self):
        return len(self.x)

    def __getitem__(self, idx):
        return self.x[idx], self.y[idx]


def make_features(in_columns, out_columns, is_training, data_dir='data'):
    save_fname = 'merged_data.pkl'

    merged_path = os.path.join(data_dir, save_fname)
    if os.path.exists(merged_path):
        print(f'loading from {merged_path}')
        table = pd.read_pickle(merged_path)
    else:
        print('merging raw csv files...')
        table = merge_data(symbols=SYMBOLS, data_dir=data_dir)
        table.to_pickle(merged_path)
        print(f'saved to {merged_path}')

    # ì „ì²˜ë¦¬
    table.dropna(subset=out_columns, inplace=True)
    table.fillna(0, inplace=True)

    # ê±°ë˜ê¸ˆì•¡ ì¶”ê°€
    table['ê±°ë˜ê¸ˆì•¡'] = table['ìˆ˜ëŸ‰'] * table['í‰ê· ê¸ˆì•¡']

    # Label Encoding for ì œí’ˆì¹´í…Œê³ ë¦¬
    le = LabelEncoder()
    table['ì œí’ˆì¹´í…Œê³ ë¦¬'] = le.fit_transform(table['ì œí’ˆì¹´í…Œê³ ë¦¬'])

    df = table[in_columns + out_columns]

    x = df[in_columns].select_dtypes(include=['int', 'float']).astype(float).to_numpy()
    y = df[out_columns].to_numpy().astype(float)

    # ë‚˜ì¤‘ì— í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• ì„ ìœ„í•´ ì•„ë˜ì²˜ëŸ¼ ìë¥¼ ìˆ˜ë„ ìˆìŒ
    if is_training:
        return x[:-100], y[:-100]
    else:
        return x[-100:], y[-100:]



def merge_data(symbols, data_dir):
    print("merging raw csv files...")
    dfs = {}

    for symbol in symbols:
        path = get_data_path(symbol, data_dir)
        df = pd.read_csv(path)
        print(f"[{symbol}] columns: {df.columns.tolist()}")
        dfs[symbol] = df

    # 1. Customer + Onlinesales on 'ê³ ê°ID'
    merged = pd.merge(dfs['Customer'], dfs['Onlinesales'], how='left', on='ê³ ê°ID')

    # 2. 'ê±°ë˜ë‚ ì§œ'ì—ì„œ 'ì›”' ì¶”ì¶œ
    if 'ê±°ë˜ë‚ ì§œ' in merged.columns:
        merged['ì›”'] = pd.to_datetime(merged['ê±°ë˜ë‚ ì§œ']).dt.month.astype(str).str.zfill(2)

    # 3. Tax ë³‘í•© on 'ì œí’ˆì¹´í…Œê³ ë¦¬'
    if 'ì œí’ˆì¹´í…Œê³ ë¦¬' in merged.columns and 'Tax' in dfs:
        merged = pd.merge(merged, dfs['Tax'], how='left', on='ì œí’ˆì¹´í…Œê³ ë¦¬')
    else:
        raise KeyError("'ì œí’ˆì¹´í…Œê³ ë¦¬'ê°€ ë³‘í•© ì¤‘ê°„ì— ì—†ìŠµë‹ˆë‹¤.")

    # 4. Discount ë³‘í•© on 'ì›”'
    if 'ì›”' in merged.columns and 'Discount' in dfs:
        discount_df = dfs['Discount'].drop(columns=['ì œí’ˆì¹´í…Œê³ ë¦¬'])
        merged = pd.merge(merged, dfs['Discount'], how='left', on='ì›”')
    else:
        raise KeyError("'ì›”' ì»¬ëŸ¼ì´ ì—†ì–´ì„œ Discount ë³‘í•© ë¶ˆê°€")
    
    # ğŸ”§ ì¤‘ë³µëœ ì œí’ˆì¹´í…Œê³ ë¦¬ ì •ë¦¬
    if 'ì œí’ˆì¹´í…Œê³ ë¦¬_x' in merged.columns:
        merged.rename(columns={'ì œí’ˆì¹´í…Œê³ ë¦¬_x': 'ì œí’ˆì¹´í…Œê³ ë¦¬'}, inplace=True)
    if 'ì œí’ˆì¹´í…Œê³ ë¦¬_y' in merged.columns:
        merged.drop(columns=['ì œí’ˆì¹´í…Œê³ ë¦¬_y'], inplace=True)

    print("ğŸ” ìµœì¢… ë³‘í•©ëœ ì»¬ëŸ¼ ëª©ë¡:", merged.columns.tolist())
    return merged


if __name__ == "__main__":
    dataset = InfoDataset(is_training=True)
    print(f"dataset length: {len(dataset)}")
    print(f"first sample x: {dataset[0][0]}")
    print(f"first sample y: {dataset[0][1]}")
